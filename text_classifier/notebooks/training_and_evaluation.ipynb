{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning a Pre-Trained Transformer for Diverse Classification\n",
    "\n",
    "This notebook takes the pre-trained encoder weights (`pretrained_transformer_encoder.pth`) and fine-tunes them on a **combined dataset** to create a versatile classifier.\n",
    "\n",
    "**Our Goal:** Build a single model that can perform both:\n",
    "1.  **Topic Classification** (using AG News)\n",
    "2.  **Sentiment Analysis** (using IMDB movie reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Device Setup\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import re\n",
    "from collections import Counter\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Model Architecture \n",
    "\n",
    "class SinusoidalPositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1), :].to(x.device)\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "        self.W_Q = nn.Linear(d_model, d_model)\n",
    "        self.W_K = nn.Linear(d_model, d_model)\n",
    "        self.W_V = nn.Linear(d_model, d_model)\n",
    "        self.W_O = nn.Linear(d_model, d_model)\n",
    "    def forward(self, x, mask=None):\n",
    "        B, L, _ = x.size()\n",
    "        Q = self.W_Q(x).view(B, L, self.num_heads, self.d_k).transpose(1,2)\n",
    "        K = self.W_K(x).view(B, L, self.num_heads, self.d_k).transpose(1,2)\n",
    "        V = self.W_V(x).view(B, L, self.num_heads, self.d_k).transpose(1,2)\n",
    "        scores = torch.matmul(Q, K.transpose(-2,-1)) / math.sqrt(self.d_k)\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1).unsqueeze(2)\n",
    "            scores = scores.masked_fill(mask == 0, torch.finfo(scores.dtype).min)\n",
    "        attn = F.softmax(scores, dim=-1)\n",
    "        out = torch.matmul(attn, V)\n",
    "        out = out.transpose(1,2).contiguous().view(B, L,  self.d_model)\n",
    "        return self.W_O(out), attn\n",
    "\n",
    "class TransformerEncoderBlock(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff):\n",
    "        super().__init__()\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.ff = nn.Sequential(nn.Linear(d_model, d_ff), nn.ReLU(), nn.Linear(d_ff, d_model))\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        \n",
    "        x_attn, _ = self.mha(x, mask)\n",
    "        x = self.norm1(x + x_attn)\n",
    "\n",
    "        x_ff = self.ff(x)\n",
    "        x = self.norm2(x + x_ff)\n",
    "        return x\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, num_layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([TransformerEncoderBlock(d_model, num_heads, d_ff) for _ in range(num_layers)])\n",
    "    def forward(self, x, mask=None):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return x\n",
    "\n",
    "class EncoderClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, num_heads, d_ff, num_layers, num_classes):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_enc = SinusoidalPositionalEncoding(d_model)\n",
    "        self.encoder = TransformerEncoder(d_model, num_heads, d_ff, num_layers)\n",
    "        self.classifier = nn.Linear(d_model, num_classes)\n",
    "    def forward(self, input_ids, mask=None):\n",
    "        embeds = self.embedding_layer(input_ids)\n",
    "        embeds_pos = self.pos_enc(embeds)\n",
    "        enc_out = self.encoder(embeds_pos, mask)\n",
    "        cls_token_out = enc_out[:, 0, :] \n",
    "        return self.classifier(cls_token_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Load, Combine, and Unify Datasets\n",
    "print(\"Loading datasets...\")\n",
    "ag_news_ds = load_dataset(\"ag_news\")\n",
    "imdb_ds = load_dataset(\"imdb\")\n",
    "\n",
    "\n",
    "unified_class_map = {\n",
    "    0: \"World News\",\n",
    "    1: \"Sports News\",\n",
    "    2: \"Business News\",\n",
    "    3: \"Sci/Tech News\",\n",
    "    4: \"Negative Review\",\n",
    "    5: \"Positive Review\"\n",
    "}\n",
    "NUM_CLASSES = len(unified_class_map)\n",
    "\n",
    "\n",
    "combined_data = []\n",
    "\n",
    "for item in ag_news_ds['train']:\n",
    "    combined_data.append({'text': item['text'], 'label': item['label']})\n",
    "\n",
    "for item in imdb_ds['train']:\n",
    "    new_label = item['label'] + 4\n",
    "    combined_data.append({'text': item['text'], 'label': new_label})\n",
    "\n",
    "import random\n",
    "random.shuffle(combined_data)\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    [item['text'] for item in combined_data],\n",
    "    [item['label'] for item in combined_data],\n",
    "    test_size=0.1, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_split = [{'text': t, 'label': l} for t, l in zip(train_texts, train_labels)]\n",
    "val_split = [{'text': t, 'label': l} for t, l in zip(val_texts, val_labels)]\n",
    "\n",
    "print(f\"Created a diverse dataset with {len(train_split)} training and {len(val_split)} validation examples.\")\n",
    "print(f\"Total number of classes: {NUM_CLASSES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Vocabulary and Dataset Class\n",
    "print(\"Building vocabulary from combined data...\")\n",
    "\n",
    "def simple_tokenizer(text):\n",
    "    return re.findall(r'\\b\\w+\\b', text.lower())\n",
    "\n",
    "word_counts = Counter()\n",
    "for example in tqdm(train_split):\n",
    "    word_counts.update(simple_tokenizer(example['text']))\n",
    "\n",
    "min_freq = 5\n",
    "vocab = {\"<pad>\": 0, \"<unk>\": 1, \"[CLS]\": 2}\n",
    "offset = len(vocab)\n",
    "for word, count in word_counts.items():\n",
    "    if count >= min_freq:\n",
    "        vocab[word] = offset\n",
    "        offset += 1\n",
    "\n",
    "VOCAB_SIZE = len(vocab)\n",
    "print(f\"Vocabulary size: {VOCAB_SIZE}\")\n",
    "\n",
    "class ClassificationDataset(Dataset):\n",
    "    def __init__(self, data, vocab, max_seq_len):\n",
    "        self.data = data\n",
    "        self.vocab = vocab\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.tokenizer = simple_tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        text, label = item['text'], item['label']\n",
    "        tokens = ['[CLS]'] + self.tokenizer(text)\n",
    "        token_ids = [self.vocab.get(token, self.vocab[\"<unk>\"]) for token in tokens]\n",
    "        \n",
    "        # Pad or truncate\n",
    "        if len(token_ids) < self.max_seq_len:\n",
    "            token_ids += [self.vocab[\"<pad>\"]] * (self.max_seq_len - len(token_ids))\n",
    "        else:\n",
    "            token_ids = token_ids[:self.max_seq_len]\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(token_ids, dtype=torch.long),\n",
    "            \"label\": torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Hyperparameters & Instantiation\n",
    "\n",
    "\n",
    "\n",
    "D_MODEL = 256\n",
    "NUM_HEADS = 8\n",
    "D_FF = 1024\n",
    "NUM_ENCODER_LAYERS = 4\n",
    "\n",
    "MAX_SEQ_LEN = 256\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 2e-5 \n",
    "EPOCHS = 3\n",
    "\n",
    "\n",
    "model = EncoderClassifier(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    d_ff=D_FF,\n",
    "    num_layers=NUM_ENCODER_LAYERS,\n",
    "    num_classes=NUM_CLASSES\n",
    ").to(device)\n",
    "\n",
    "ENCODER_WEIGHTS_PATH = 'pretrained_transformer_encoder.pth'\n",
    "print(f\"Loading pre-trained encoder weights from {ENCODER_WEIGHTS_PATH}\")\n",
    "model.encoder.load_state_dict(torch.load(ENCODER_WEIGHTS_PATH, map_location=device))\n",
    "print(\"âœ… Weights loaded successfully!\")\n",
    "\n",
    "train_dataset = ClassificationDataset(train_split, vocab, MAX_SEQ_LEN)\n",
    "val_dataset = ClassificationDataset(val_split, vocab, MAX_SEQ_LEN)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Training and Evaluation Loops\n",
    "\n",
    "def train_epoch(model, dataloader, loss_fn, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "        padding_mask = (input_ids != vocab[\"<pad>\"]).to(device)\n",
    "        logits = model(input_ids, mask=padding_mask)\n",
    "        loss = loss_fn(logits, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "        total_correct += (predictions == labels).sum().item()\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = total_correct / len(dataloader.dataset)\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def evaluate(model, dataloader, loss_fn, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "            padding_mask = (input_ids != vocab[\"<pad>\"]).to(device)\n",
    "            logits = model(input_ids, mask=padding_mask)\n",
    "            loss = loss_fn(logits, labels)\n",
    "            total_loss += loss.item()\n",
    "            predictions = torch.argmax(logits, dim=1)\n",
    "            total_correct += (predictions == labels).sum().item()\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = total_correct / len(dataloader.dataset)\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7 (REVISED): Main Fine-Tuning Execution with Freezing\n",
    "\n",
    "print(\"--- Stage 1: Training the Classifier Head (Encoder Frozen) ---\")\n",
    "\n",
    "for param in model.encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print(\"\\n--- Epoch 1/4 ---\")\n",
    "train_loss, train_acc = train_epoch(model, train_loader, loss_fn, optimizer, device)\n",
    "print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "val_loss, val_acc = evaluate(model, val_loader, loss_fn, device)\n",
    "print(f\"Validation Loss: {val_loss:.4f} | Validation Acc: {val_acc:.4f}\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Stage 2: Fine-Tuning the Full Model (Encoder Unfrozen) ---\")\n",
    "\n",
    "for param in model.encoder.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "for epoch in range(1, EPOCHS + 1): \n",
    "    print(f\"\\n--- Epoch {epoch + 1}/4 ---\")\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, loss_fn, optimizer, device)\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    val_loss, val_acc = evaluate(model, val_loader, loss_fn, device)\n",
    "    print(f\"Validation Loss: {val_loss:.4f} | Validation Acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Inference with the Diverse Classifier\n",
    "\n",
    "def predict_category(text, model, vocab, class_map, max_len, device):\n",
    "    model.eval()\n",
    "    tokens = ['[CLS]'] + simple_tokenizer(text)\n",
    "    token_ids = [vocab.get(t, vocab[\"<unk>\"]) for t in tokens]\n",
    "    if len(token_ids) < max_len:\n",
    "        token_ids += [vocab[\"<pad>\"]] * (max_len - len(token_ids))\n",
    "    else:\n",
    "        token_ids = token_ids[:max_len]\n",
    "        \n",
    "    input_tensor = torch.tensor([token_ids], dtype=torch.long).to(device)\n",
    "    mask = (input_tensor != vocab[\"<pad>\"]).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor, mask=mask)\n",
    "        \n",
    "    pred_index = torch.argmax(logits, dim=1).item()\n",
    "    return class_map[pred_index]\n",
    "\n",
    "news_headline = \"The space agency announced a new mission to Mars to search for signs of ancient life.\"\n",
    "movie_review_1 = \"The movie was absolutely fantastic! The acting was superb and the plot was thrilling.\"\n",
    "movie_review_2 = \"I was so bored throughout the entire film. It was a complete waste of time.\"\n",
    "\n",
    "print(f\"'{news_headline}' -> Prediction: {predict_category(news_headline, model, vocab, unified_class_map, MAX_SEQ_LEN, device)}\")\n",
    "print(f\"'{movie_review_1}' -> Prediction: {predict_category(movie_review_1, model, vocab, unified_class_map, MAX_SEQ_LEN, device)}\")\n",
    "print(f\"'{movie_review_2}' -> Prediction: {predict_category(movie_review_2, model, vocab, unified_class_map, MAX_SEQ_LEN, device)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this code to the end of your fine-tuning notebook\n",
    "\n",
    "FINETUNED_MODEL_PATH = 'finetuned_diverse_classifier.pth'\n",
    "torch.save(model.state_dict(), FINETUNED_MODEL_PATH)\n",
    "print(f\"Fine-tuned model saved to {FINETUNED_MODEL_PATH}\")\n",
    "\n",
    "FINETUNED_VOCAB_PATH = 'finetuned_vocab.json'\n",
    "with open(FINETUNED_VOCAB_PATH, 'w') as f:\n",
    "    json.dump(vocab, f, indent=4)\n",
    "print(f\"Fine-tuned vocabulary saved to {FINETUNED_VOCAB_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
